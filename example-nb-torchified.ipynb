{
	"cells": [
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"source: https://www.kaggle.com/code/philculliton/inferring-birds-with-kaggle-models"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Step 1: Imports"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
				"_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
				"execution": {
					"iopub.execute_input": "2023-03-29T06:38:42.021281Z",
					"iopub.status.busy": "2023-03-29T06:38:42.019762Z",
					"iopub.status.idle": "2023-03-29T06:38:42.028449Z",
					"shell.execute_reply": "2023-03-29T06:38:42.027144Z",
					"shell.execute_reply.started": "2023-03-29T06:38:42.021210Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"import tensorflow as tf\n",
				"import tensorflow_hub as hub\n",
				"import pandas as pd\n",
				"import numpy as np\n",
				"import librosa\n",
				"import torch\n",
				"from IPython.display import Audio\n",
				"\n",
				"import random\n",
				"import glob\n",
				"import os\n",
				"import csv\n",
				"import io\n",
				"\n",
				"import utils"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"RANDOM_SEED = 21\n",
				"\n",
				"# Set seed for experiment reproducibility\n",
				"random.seed(RANDOM_SEED)\n",
				"tf.random.set_seed(RANDOM_SEED)\n",
				"np.random.seed(RANDOM_SEED)\n",
				"torch.manual_seed(RANDOM_SEED)\n",
				"torch.cuda.manual_seed(RANDOM_SEED)\n",
				"torch.backends.cudnn.deterministic = True\n",
				"torch.backends.cudnn.benchmark = True"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"is_in_kaggle_env = utils.get_is_in_kaggle_env()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"data_path = '/kaggle/input/birdclef-2023' if is_in_kaggle_env else 'data'"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"device = 'cpu' if is_in_kaggle_env else utils.determine_device()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"if not is_in_kaggle_env and not os.path.exists('data'):\n",
				"    !kaggle competitions download -c 'birdclef-2023'\n",
				"    !mkdir data\n",
				"    !unzip -q birdclef-2023.zip -d data\n",
				"    !rm birdclef-2023.zip"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Step 2: Explore the training data\n",
				"\n",
				"We'll start by loading a couple of training examples and using the IPython.display.Audio module to play them!"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:38:42.032075Z",
					"iopub.status.busy": "2023-03-29T06:38:42.031143Z",
					"iopub.status.idle": "2023-03-29T06:38:54.752752Z",
					"shell.execute_reply": "2023-03-29T06:38:54.751558Z",
					"shell.execute_reply.started": "2023-03-29T06:38:42.032025Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"# Load a sample audio files from two different species\n",
				"audio_abe, sr_abe = librosa.load(f\"{data_path}/train_audio/abethr1/XC128013.ogg\")\n",
				"audio_abh, sr_abh = librosa.load(f\"{data_path}/train_audio/abhori1/XC127317.ogg\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:38:54.756504Z",
					"iopub.status.busy": "2023-03-29T06:38:54.754627Z",
					"iopub.status.idle": "2023-03-29T06:38:54.836497Z",
					"shell.execute_reply": "2023-03-29T06:38:54.835538Z",
					"shell.execute_reply.started": "2023-03-29T06:38:54.756432Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"# Play the audio\n",
				"Audio(data=audio_abe, rate=sr_abe)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:38:54.840963Z",
					"iopub.status.busy": "2023-03-29T06:38:54.840227Z",
					"iopub.status.idle": "2023-03-29T06:38:54.906829Z",
					"shell.execute_reply": "2023-03-29T06:38:54.905150Z",
					"shell.execute_reply.started": "2023-03-29T06:38:54.840918Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"# Play the audio\n",
				"Audio(data=audio_abh, rate=sr_abh)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Step 3: Match the model's output with the bird species in the competition\n",
				"\n",
				"The competition includes 264 classes of birds, 261 of which exist in this model. We'll set up a way to map the model's output logits to our competition."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:38:54.909410Z",
					"iopub.status.busy": "2023-03-29T06:38:54.908958Z",
					"iopub.status.idle": "2023-03-29T06:39:03.540408Z",
					"shell.execute_reply": "2023-03-29T06:39:03.539059Z",
					"shell.execute_reply.started": "2023-03-29T06:38:54.909361Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"model = hub.load('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/1')\n",
				"labels_path = hub.resolve('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/1') + \"/assets/label.csv\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:03.543154Z",
					"iopub.status.busy": "2023-03-29T06:39:03.542308Z",
					"iopub.status.idle": "2023-03-29T06:39:03.562694Z",
					"shell.execute_reply": "2023-03-29T06:39:03.561368Z",
					"shell.execute_reply.started": "2023-03-29T06:39:03.543102Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"# Find the name of the class with the top score when mean-aggregated across frames.\n",
				"def class_names_from_csv(class_map_csv_text):\n",
				"    \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
				"    with open(labels_path) as csv_file:\n",
				"        csv_reader = csv.reader(csv_file, delimiter=',')\n",
				"        class_names = [mid for mid, desc in csv_reader]\n",
				"        return class_names[1:]\n",
				"\n",
				"## note that the bird classifier classifies a much larger set of birds than the\n",
				"## competition, so we need to load the model's set of class names or else our \n",
				"## indices will be off.\n",
				"classes = class_names_from_csv(labels_path)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:03.564755Z",
					"iopub.status.busy": "2023-03-29T06:39:03.564382Z",
					"iopub.status.idle": "2023-03-29T06:39:03.743900Z",
					"shell.execute_reply": "2023-03-29T06:39:03.742564Z",
					"shell.execute_reply.started": "2023-03-29T06:39:03.564719Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"train_metadata = pd.read_csv(f\"{data_path}/train_metadata.csv\")\n",
				"train_metadata.head()\n",
				"competition_classes = sorted(train_metadata.primary_label.unique())\n",
				"\n",
				"forced_defaults = 0\n",
				"competition_class_map = []\n",
				"for c in competition_classes:\n",
				"    try:\n",
				"        i = classes.index(c)\n",
				"        competition_class_map.append(i)\n",
				"    except:\n",
				"        competition_class_map.append(0)\n",
				"        forced_defaults += 1\n",
				"        \n",
				"## this is the count of classes not supported by our pretrained model\n",
				"## you could choose to simply not predict these, set a default as above,\n",
				"## or create your own model using the pretrained model as a base.\n",
				"forced_defaults"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Step 4: Preprocess the data\n",
				"\n",
				"The following functions are one way to load the audio provided and break it up into the five-second samples with a sample rate of 32,000 required by the competition."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:03.745983Z",
					"iopub.status.busy": "2023-03-29T06:39:03.745636Z",
					"iopub.status.idle": "2023-03-29T06:39:03.754203Z",
					"shell.execute_reply": "2023-03-29T06:39:03.753014Z",
					"shell.execute_reply.started": "2023-03-29T06:39:03.745950Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"def frame_audio(\n",
				"      audio_array: np.ndarray,\n",
				"      window_size_s: float = 5.0,\n",
				"      hop_size_s: float = 5.0,\n",
				"      sample_rate = 32000,\n",
				"      ) -> np.ndarray:\n",
				"    \n",
				"    \"\"\"Helper function for framing audio for inference.\"\"\"\n",
				"    if window_size_s is None or window_size_s < 0:\n",
				"        return audio_array[np.newaxis, :]\n",
				"    frame_length = int(window_size_s * sample_rate)\n",
				"    hop_length = int(hop_size_s * sample_rate)\n",
				"    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n",
				"    return framed_audio"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def ensure_sample_rate(waveform, original_sample_rate, desired_sample_rate=32000):\n",
				"    \"\"\"Resample waveform if required.\"\"\"\n",
				"    if original_sample_rate != desired_sample_rate:\n",
				"        waveform = librosa.resample(waveform, orig_sr=original_sample_rate, target_sr=desired_sample_rate)\n",
				"    return desired_sample_rate, waveform"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Below we load one training sample - use the Audio function to listen to the samples inside the notebook!"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:03.756131Z",
					"iopub.status.busy": "2023-03-29T06:39:03.755785Z",
					"iopub.status.idle": "2023-03-29T06:39:04.522415Z",
					"shell.execute_reply": "2023-03-29T06:39:04.521358Z",
					"shell.execute_reply.started": "2023-03-29T06:39:03.756100Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"audio, sample_rate = librosa.load(f\"{data_path}/train_audio/afghor1/XC156639.ogg\")\n",
				"sample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\n",
				"Audio(wav_data, rate=sample_rate)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Step 5: Make predictions\n",
				"\n",
				"Each test sample is cut into 5-second chunks. We use the pretrained model to return probabilities for all 10k birds included in the model, then pull out the classes used in this competition to create a final submission row. Note that we are NOT doing anything special to handle the 3 missing classes; those will need fine-tuning / transfer learning, which will be handled in a separate notebook."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:04.526545Z",
					"iopub.status.busy": "2023-03-29T06:39:04.525536Z",
					"iopub.status.idle": "2023-03-29T06:39:15.220173Z",
					"shell.execute_reply": "2023-03-29T06:39:15.218802Z",
					"shell.execute_reply.started": "2023-03-29T06:39:04.526502Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"fixed_tm = frame_audio(wav_data)\n",
				"logits, embeddings = model.infer_tf(fixed_tm[:1])\n",
				"probabilities = tf.nn.softmax(logits)\n",
				"argmax = np.argmax(probabilities)\n",
				"print(f\"The audio is from the class {classes[argmax]} (element:{argmax} in the label.csv file), with probability of {probabilities[0][argmax]}\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:15.222979Z",
					"iopub.status.busy": "2023-03-29T06:39:15.221773Z",
					"iopub.status.idle": "2023-03-29T06:39:15.234871Z",
					"shell.execute_reply": "2023-03-29T06:39:15.233204Z",
					"shell.execute_reply.started": "2023-03-29T06:39:15.222926Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"def predict_for_sample(filename, sample_submission, frame_limit_secs=None):\n",
				"    file_id = filename.split(\".ogg\")[0].split(\"/\")[-1]\n",
				"    \n",
				"    audio, sample_rate = librosa.load(filename)\n",
				"    sample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\n",
				"    \n",
				"    fixed_tm = frame_audio(wav_data)\n",
				"    frame_length = int(5 * sample_rate)\n",
				"    \n",
				"    all_logits, all_embeddings = model.infer(torch.tensor(fixed_tm[:1]))\n",
				"    for window in fixed_tm[1:]:\n",
				"        if frame_limit_secs and frame_length / sample_rate > frame_limit_secs:\n",
				"            continue\n",
				"        \n",
				"        logits, embeddings = model.infer(torch.tensor(window[np.newaxis, :]))\n",
				"        all_logits = torch.cat([all_logits, logits], dim=0)\n",
				"        frame_length += int(5 * sample_rate)\n",
				"    \n",
				"    all_probabilities = []\n",
				"    for frame_logits in all_logits:\n",
				"        probabilities = torch.nn.functional.softmax(frame_logits, dim=0).numpy()\n",
				"        \n",
				"        ## set the appropriate row in the sample submission\n",
				"        sample_submission.loc[sample_submission.row_id == file_id + \"_\" + str(frame_length // sample_rate), competition_classes] = probabilities[competition_class_map]\n",
				"        frame_length += int(5 * sample_rate)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Step 6: Generate a submission\n",
				"\n",
				"Now we process all of the test samples as discussed above, creating output rows, and saving them in the provided `sample_submission.csv`. Finally, we save these rows to our final output file: `submission.csv`. This is the file that gets submitted and scored when you submit the notebook."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:15.237083Z",
					"iopub.status.busy": "2023-03-29T06:39:15.236208Z",
					"iopub.status.idle": "2023-03-29T06:39:15.259170Z",
					"shell.execute_reply": "2023-03-29T06:39:15.258163Z",
					"shell.execute_reply.started": "2023-03-29T06:39:15.237044Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"test_samples = list(glob.glob(\"/kaggle/input/birdclef-2023/test_soundscapes/*.ogg\"))\n",
				"test_samples"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:15.260890Z",
					"iopub.status.busy": "2023-03-29T06:39:15.260397Z",
					"iopub.status.idle": "2023-03-29T06:39:15.374308Z",
					"shell.execute_reply": "2023-03-29T06:39:15.372994Z",
					"shell.execute_reply.started": "2023-03-29T06:39:15.260855Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"sample_sub = pd.read_csv(f\"{data_path}/sample_submission.csv\")\n",
				"sample_sub[competition_classes] = sample_sub[competition_classes].astype(np.float32)\n",
				"sample_sub.head()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:15.376259Z",
					"iopub.status.busy": "2023-03-29T06:39:15.375905Z",
					"iopub.status.idle": "2023-03-29T06:39:27.044981Z",
					"shell.execute_reply": "2023-03-29T06:39:27.043566Z",
					"shell.execute_reply.started": "2023-03-29T06:39:15.376224Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"frame_limit_secs = 15 if sample_sub.shape[0] == 3 else None\n",
				"for sample_filename in test_samples:\n",
				"    predict_for_sample(sample_filename, sample_sub, frame_limit_secs=15)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:27.047187Z",
					"iopub.status.busy": "2023-03-29T06:39:27.046788Z",
					"iopub.status.idle": "2023-03-29T06:39:27.076825Z",
					"shell.execute_reply": "2023-03-29T06:39:27.075621Z",
					"shell.execute_reply.started": "2023-03-29T06:39:27.047148Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"sample_sub"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"execution": {
					"iopub.execute_input": "2023-03-29T06:39:27.078605Z",
					"iopub.status.busy": "2023-03-29T06:39:27.078215Z",
					"iopub.status.idle": "2023-03-29T06:39:27.099725Z",
					"shell.execute_reply": "2023-03-29T06:39:27.098524Z",
					"shell.execute_reply.started": "2023-03-29T06:39:27.078570Z"
				},
				"trusted": true
			},
			"outputs": [],
			"source": [
				"sample_sub.to_csv(f\"{data_path}/submission.csv\", index=False)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.10"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
