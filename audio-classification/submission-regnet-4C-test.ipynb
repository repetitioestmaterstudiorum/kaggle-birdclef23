{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ebd60c0",
   "metadata": {},
   "source": [
    "# RegNet Inference (submission generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b594cdc3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:42.750183Z",
     "iopub.status.busy": "2023-04-14T04:40:42.749779Z",
     "iopub.status.idle": "2023-04-14T04:40:47.150440Z",
     "shell.execute_reply": "2023-04-14T04:40:47.149088Z"
    },
    "papermill": {
     "duration": 4.409497,
     "end_time": "2023-04-14T04:40:47.153201",
     "exception": false,
     "start_time": "2023-04-14T04:40:42.743704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from torchvision.models import regnet_y_800mf, RegNet_Y_800MF_Weights\n",
    "import timm\n",
    "import re\n",
    "from torchaudio import functional as F_audio\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be457b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are running code on Localhost\n"
     ]
    }
   ],
   "source": [
    "## REUSE IN INFERENCE NOTEBOOK\n",
    "\n",
    "custom_dataset_path = '/kaggle/input/birdclef2023-inference'\n",
    "if os.path.exists(os.path.join(custom_dataset_path, 'utils.py')):\n",
    "    sys.path.append(custom_dataset_path)\n",
    "else:\n",
    "    sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "IS_IN_KAGGLE_ENV = utils.get_is_in_kaggle_env()\n",
    "\n",
    "DATA_PATH = '/kaggle/input/birdclef-2023' if IS_IN_KAGGLE_ENV else '../data'\n",
    "JOBLIB_PATH = custom_dataset_path if IS_IN_KAGGLE_ENV else './'\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "AUDIO_LENGTH_S = 5\n",
    "SAMPLE_RATE = 32_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d2a40c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:47.281054Z",
     "iopub.status.busy": "2023-04-14T04:40:47.280329Z",
     "iopub.status.idle": "2023-04-14T04:40:47.286543Z",
     "shell.execute_reply": "2023-04-14T04:40:47.285263Z"
    },
    "papermill": {
     "duration": 0.013263,
     "end_time": "2023-04-14T04:40:47.289034",
     "exception": false,
     "start_time": "2023-04-14T04:40:47.275771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## REUSE IN INFERENCE NOTEBOOK\n",
    "\n",
    "class BirdMelspecClf(nn.Module):\n",
    "    def __init__(self, out_features, pretrained):\n",
    "        super().__init__()\n",
    "        \n",
    "        # https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "        self.regnet = regnet_y_800mf(weights=RegNet_Y_800MF_Weights.DEFAULT) if pretrained else regnet_y_800mf()\n",
    "\n",
    "        \"\"\"\n",
    "        Original:\n",
    "        RegnetCNN(\n",
    "        (regnet): RegNet(\n",
    "            (stem): SimpleStemIN(\n",
    "            (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU(inplace=True)\n",
    "        )\"\"\"\n",
    "        self.regnet.stem = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Fine-tune the regnet classifier\n",
    "        self.regnet.fc = nn.Linear(self.regnet.fc.in_features, out_features)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        logits = self.regnet(x)\n",
    "        probas = self.softmax(logits)\n",
    "\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "def get_model(out_features, device, pretrained=False, load_state_dict=True, state_dict_starts_with=f\"{AUDIO_LENGTH_S}s_regnetY800MF_\"):\n",
    "    model = BirdMelspecClf(out_features=out_features, pretrained=pretrained)\n",
    "    print(f\"Loaded model {model.__class__.__name__} with {sum(p.numel() for p in model.parameters())} parameters, pretained={pretrained}\")\n",
    "    model.to(device)\n",
    "\n",
    "    if not load_state_dict:\n",
    "        return model\n",
    "\n",
    "    model_files = [f for f in os.listdir(JOBLIB_PATH) if f.startswith(state_dict_starts_with) and f.endswith('.pt')]\n",
    "    if len(model_files) == 0:\n",
    "        print(f\"No model starting with {state_dict_starts_with} found in {JOBLIB_PATH}\")\n",
    "        return model\n",
    "    \n",
    "    # Extract timestamp from the filenames and sort based on it\n",
    "    model_files.sort(key=lambda x: int(re.findall(r'\\d+', x)[-1]) if re.findall(r'\\d+', x) else -1)\n",
    "\n",
    "    # The latest model file is the last one in the sorted list\n",
    "    latest_model_file = model_files[-1]\n",
    "    model_path = os.path.join(JOBLIB_PATH, latest_model_file)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Loaded model weights from {model_path}\")\n",
    "    model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_label_encoder():\n",
    "    label_encoder_path = os.path.join(JOBLIB_PATH, 'label_encoder.joblib')\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"Loaded label encoder from {label_encoder_path}\")\n",
    "    return label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63a5798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletTransformSingle(nn.Module):\n",
    "  def __init__(\n",
    "      self, \n",
    "      wavelet: pywt.Wavelet,\n",
    "      cut_to_nearest: int | None = None\n",
    "  ):\n",
    "    super(WaveletTransformSingle, self).__init__()\n",
    "    self.wavelet = wavelet\n",
    "    self.ctn = cut_to_nearest\n",
    "\n",
    "  def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "    item = X.cpu().numpy()\n",
    "    \n",
    "    wh, wl = pywt.dwt(item[0], self.wavelet)\n",
    "    out = torch.stack((torch.from_numpy(wh), torch.from_numpy(wl)))\n",
    "    \n",
    "    if self.ctn is not None:\n",
    "      out = out[:,:-1 * (out.shape[-1] % self.ctn)]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b0daee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioAugmentations(nn.Module):\n",
    "  def __init__(\n",
    "      self, \n",
    "      stretch_rate=0.8,\n",
    "      fixed_rate=True,\n",
    "      freq_mask_param=30,\n",
    "      time_mask_param=80\n",
    "  ):\n",
    "    super(AudioAugmentations, self).__init__()\n",
    "    self.aug = nn.Sequential(\n",
    "        torchaudio.transforms.TimeStretch(stretch_rate, fixed_rate=fixed_rate),\n",
    "        torchaudio.transforms.FrequencyMasking(freq_mask_param=freq_mask_param),\n",
    "        torchaudio.transforms.TimeMasking(time_mask_param=time_mask_param),\n",
    "    )\n",
    "  \n",
    "  def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "    return self.aug(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "456150a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:47.167665Z",
     "iopub.status.busy": "2023-04-14T04:40:47.167337Z",
     "iopub.status.idle": "2023-04-14T04:40:47.263629Z",
     "shell.execute_reply": "2023-04-14T04:40:47.262092Z"
    },
    "papermill": {
     "duration": 0.103522,
     "end_time": "2023-04-14T04:40:47.266309",
     "exception": false,
     "start_time": "2023-04-14T04:40:47.162787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## REUSE IN INFERENCE NOTEBOOK\n",
    "\n",
    "def resample(audio, current_sample_rate, desired_sample_rate=SAMPLE_RATE):\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=current_sample_rate, new_freq=desired_sample_rate)\n",
    "    resampled_audio = resampler(audio)\n",
    "    return resampled_audio\n",
    "\n",
    "def load_audio(audio_path, sample_rate=SAMPLE_RATE):\n",
    "    audio, sr = torchaudio.load(audio_path)\n",
    "    if sr != sample_rate:\n",
    "        audio = resample(audio, sr, sample_rate)\n",
    "    return audio\n",
    "\n",
    "# Using librosa defaults for n_fft and hop_length\n",
    "def get_melspec_transform(sample_rate=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    return torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "    )\n",
    "\n",
    "# Using librosa defaults for top_db\n",
    "def get_melspec_db_transform(stype='power', top_db=80):\n",
    "    return torchaudio.transforms.AmplitudeToDB(\n",
    "        stype=stype,\n",
    "        top_db=top_db\n",
    "    )\n",
    "\n",
    "# Copied from torchaudio/transforms/_transforms.py (to avoid converting to melspec twice)\n",
    "dct_mat = F_audio.create_dct(40, 128, \"ortho\")\n",
    "def get_mfcc_from_melspec(melspec):\n",
    "    return torch.matmul(melspec.transpose(-1, -2), dct_mat).transpose(-1, -2)\n",
    "\n",
    "def normalize_tensor(tensor):\n",
    "    min_val = torch.min(tensor)\n",
    "    max_val = torch.max(tensor)\n",
    "    if max_val - min_val == 0:\n",
    "        return tensor\n",
    "    else:\n",
    "        return (tensor - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1ac267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepaths length: 1 (amount of test soundscapes)\n"
     ]
    }
   ],
   "source": [
    "filepaths = glob.glob(f\"{DATA_PATH}/test_soundscapes/*.ogg\")\n",
    "print(f\"filepaths length: {len(filepaths)} (amount of test soundscapes)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75cb3717",
   "metadata": {
    "papermill": {
     "duration": 0.002934,
     "end_time": "2023-04-14T04:40:48.158297",
     "exception": false,
     "start_time": "2023-04-14T04:40:48.155363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aca7fea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:48.166858Z",
     "iopub.status.busy": "2023-04-14T04:40:48.165617Z",
     "iopub.status.idle": "2023-04-14T04:40:57.513978Z",
     "shell.execute_reply": "2023-04-14T04:40:57.512914Z"
    },
    "papermill": {
     "duration": 9.356216,
     "end_time": "2023-04-14T04:40:57.517571",
     "exception": false,
     "start_time": "2023-04-14T04:40:48.161355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded label encoder from ./label_encoder.joblib\n",
      "Loaded model BirdMelspecClf with 5855040 parameters, pretained=False\n",
      "No model starting with 5s_regnetY800MF_ found in ./\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infering files: 100%|██████████| 1/1 [00:00<00:00, 718.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_preds length: 1, all_preds_flat length: 120\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "debug = False\n",
    "simulate_200_files = False\n",
    "\n",
    "if simulate_200_files:\n",
    "    filepaths = [filepaths[0] for i in range(200)] # simulate submission\n",
    "    print(f\"filepaths length: {len(filepaths)} after simulation additions\")\n",
    "\n",
    "label_encoder = get_label_encoder()\n",
    "model = get_model(out_features=len(label_encoder.classes_), device=DEVICE, pretrained=False, load_state_dict=True)\n",
    "model.eval()\n",
    "\n",
    "MIN_WINDOW = AUDIO_LENGTH_S * SAMPLE_RATE\n",
    "melspec_transform = get_melspec_transform(n_mels=128)\n",
    "melspec_db_transform = get_melspec_db_transform()\n",
    "wave_transform = WaveletTransformSingle(pywt.Wavelet('sym4'))\n",
    "resize = transforms.Resize((128, 313), antialias=True)\n",
    "\n",
    "def infer(filepath):\n",
    "    all_predictions = []\n",
    "    name = Path(filepath).stem\n",
    "    audio = load_audio(filepath)\n",
    "    audio_len_s = audio.shape[1] / SAMPLE_RATE\n",
    "    debug and print(f\"Infering file {filepath} with length {audio_len_s} s\")\n",
    "    n_crops = int(audio_len_s // 5)\n",
    "    for i in range(n_crops):\n",
    "        debug and print(f\"Crop {i} / {n_crops}\")\n",
    "        debug and print(f\"Audio length: {len(audio)}\")\n",
    "        crop = audio[:, i*MIN_WINDOW:(i+1)*MIN_WINDOW]\n",
    "        debug and print(f\"Crop dimensions: {crop.shape}\")\n",
    "        melspec = melspec_db_transform(melspec_transform(crop))\n",
    "        norm_melspec = normalize_tensor(melspec)\n",
    "        melspec_wave = wave_transform(crop)\n",
    "        wh, wl = melspec_wave[0], melspec_wave[1]\n",
    "        wh_mel = melspec_db_transform(melspec_transform(wh))\n",
    "        wl_mel = melspec_db_transform(melspec_transform(wl))\n",
    "        norm_wh = normalize_tensor(resize(wh_mel.unsqueeze(0)))\n",
    "        norm_wl = normalize_tensor(resize(wl_mel.unsqueeze(0)))\n",
    "        mfcc = get_mfcc_from_melspec(melspec)\n",
    "        norm_mfcc = normalize_tensor(resize(mfcc))\n",
    "        features = torch.cat((norm_melspec, norm_wh, norm_wl, norm_mfcc), dim=0)\n",
    "        debug and print(f\"features shape: {features.shape}\") # [4, 128, 313]\n",
    "        features = features.unsqueeze(0) # add batch dimension (1)\n",
    "        debug and print(f\"features unsqueezed shape: {features.shape}\") # [1, 4, 128, 313]\n",
    "        with torch.no_grad():\n",
    "            logit, proba = model(features)\n",
    "        t = (i + 1) * 5\n",
    "        all_predictions.append({\"row_id\": f'{name}_{t}',\"predictions\": proba})\n",
    "        debug and print('---')\n",
    "    return all_predictions\n",
    "\n",
    "if debug:\n",
    "    all_preds = []\n",
    "    for filepath in tqdm(filepaths, desc='Infering files'):\n",
    "        all_preds.append(infer(filepath))\n",
    "else:\n",
    "    parallel_task = (delayed(infer)(filepath) for filepath in tqdm(filepaths, desc='Infering files'))\n",
    "    all_preds = Parallel(n_jobs=os.cpu_count())(parallel_task)\n",
    "\n",
    "all_preds_flat = [item for sublist in all_preds for item in sublist]\n",
    "\n",
    "print(f\"all_preds length: {len(all_preds)}, all_preds_flat length: {len(all_preds_flat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "654b92e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0039, 0.0038, 0.0036, 0.0037, 0.0039, 0.0038, 0.0037, 0.0036, 0.0037,\n",
       "        0.0039, 0.0038, 0.0038, 0.0038, 0.0037, 0.0039, 0.0036, 0.0040, 0.0037,\n",
       "        0.0038, 0.0039, 0.0040, 0.0038, 0.0038, 0.0037, 0.0039, 0.0037, 0.0040,\n",
       "        0.0037, 0.0038, 0.0037, 0.0036, 0.0038, 0.0036, 0.0038, 0.0038, 0.0037,\n",
       "        0.0039, 0.0038, 0.0036, 0.0036, 0.0040, 0.0036, 0.0039, 0.0040, 0.0038,\n",
       "        0.0037, 0.0036, 0.0039, 0.0037, 0.0038, 0.0039, 0.0038, 0.0038, 0.0038,\n",
       "        0.0039, 0.0038, 0.0039, 0.0038, 0.0038, 0.0039, 0.0039, 0.0039, 0.0040,\n",
       "        0.0040, 0.0037, 0.0036, 0.0038, 0.0040, 0.0038, 0.0036, 0.0038, 0.0038,\n",
       "        0.0036, 0.0037, 0.0037, 0.0040, 0.0036, 0.0039, 0.0039, 0.0036, 0.0037,\n",
       "        0.0036, 0.0037, 0.0038, 0.0036, 0.0039, 0.0039, 0.0036, 0.0038, 0.0037,\n",
       "        0.0037, 0.0037, 0.0037, 0.0034, 0.0037, 0.0037, 0.0036, 0.0036, 0.0037,\n",
       "        0.0039, 0.0038, 0.0037, 0.0038, 0.0036, 0.0036, 0.0038, 0.0039, 0.0038,\n",
       "        0.0038, 0.0037, 0.0039, 0.0036, 0.0037, 0.0039, 0.0038, 0.0038, 0.0038,\n",
       "        0.0039, 0.0036, 0.0036, 0.0039, 0.0038, 0.0037, 0.0040, 0.0039, 0.0038,\n",
       "        0.0038, 0.0036, 0.0037, 0.0038, 0.0040, 0.0037, 0.0038, 0.0037, 0.0039,\n",
       "        0.0037, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0038, 0.0038, 0.0039,\n",
       "        0.0038, 0.0039, 0.0038, 0.0037, 0.0038, 0.0038, 0.0038, 0.0039, 0.0038,\n",
       "        0.0036, 0.0038, 0.0041, 0.0038, 0.0039, 0.0040, 0.0040, 0.0036, 0.0038,\n",
       "        0.0038, 0.0038, 0.0038, 0.0036, 0.0038, 0.0038, 0.0039, 0.0037, 0.0039,\n",
       "        0.0037, 0.0040, 0.0038, 0.0038, 0.0038, 0.0038, 0.0037, 0.0040, 0.0037,\n",
       "        0.0039, 0.0039, 0.0038, 0.0038, 0.0037, 0.0038, 0.0038, 0.0037, 0.0038,\n",
       "        0.0037, 0.0038, 0.0038, 0.0037, 0.0038, 0.0038, 0.0038, 0.0036, 0.0039,\n",
       "        0.0038, 0.0037, 0.0038, 0.0037, 0.0038, 0.0040, 0.0039, 0.0040, 0.0035,\n",
       "        0.0039, 0.0040, 0.0038, 0.0037, 0.0039, 0.0037, 0.0039, 0.0037, 0.0038,\n",
       "        0.0039, 0.0037, 0.0039, 0.0038, 0.0038, 0.0037, 0.0038, 0.0037, 0.0037,\n",
       "        0.0038, 0.0038, 0.0038, 0.0037, 0.0037, 0.0038, 0.0038, 0.0038, 0.0037,\n",
       "        0.0039, 0.0039, 0.0038, 0.0038, 0.0038, 0.0038, 0.0038, 0.0038, 0.0036,\n",
       "        0.0038, 0.0038, 0.0039, 0.0039, 0.0037, 0.0040, 0.0038, 0.0037, 0.0037,\n",
       "        0.0039, 0.0036, 0.0038, 0.0039, 0.0038, 0.0036, 0.0037, 0.0038, 0.0038,\n",
       "        0.0037, 0.0038, 0.0037])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds_flat[100]['predictions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77cb8d6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:57.528394Z",
     "iopub.status.busy": "2023-04-14T04:40:57.527976Z",
     "iopub.status.idle": "2023-04-14T04:40:57.575383Z",
     "shell.execute_reply": "2023-04-14T04:40:57.574650Z"
    },
    "papermill": {
     "duration": 0.055654,
     "end_time": "2023-04-14T04:40:57.577885",
     "exception": false,
     "start_time": "2023-04-14T04:40:57.522231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>abethr1</th>\n",
       "      <th>abhori1</th>\n",
       "      <th>abythr1</th>\n",
       "      <th>afbfly1</th>\n",
       "      <th>afdfly1</th>\n",
       "      <th>afecuc1</th>\n",
       "      <th>affeag1</th>\n",
       "      <th>afgfly1</th>\n",
       "      <th>afghor1</th>\n",
       "      <th>...</th>\n",
       "      <th>yebsto1</th>\n",
       "      <th>yeccan1</th>\n",
       "      <th>yefcan</th>\n",
       "      <th>yelbis1</th>\n",
       "      <th>yenspu1</th>\n",
       "      <th>yertin1</th>\n",
       "      <th>yesbar1</th>\n",
       "      <th>yespet1</th>\n",
       "      <th>yetgre1</th>\n",
       "      <th>yewgre1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_29201_5</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_29201_10</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_29201_15</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.003708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_29201_20</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.003706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_29201_25</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.003705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>soundscape_29201_580</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.003704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>soundscape_29201_585</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>soundscape_29201_590</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>soundscape_29201_595</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.003705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>soundscape_29201_600</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.003704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   row_id   abethr1   abhori1   abythr1   afbfly1   afdfly1  \\\n",
       "0      soundscape_29201_5  0.003870  0.003786  0.003631  0.003702  0.003928   \n",
       "1     soundscape_29201_10  0.003872  0.003786  0.003628  0.003698  0.003926   \n",
       "2     soundscape_29201_15  0.003869  0.003788  0.003635  0.003703  0.003929   \n",
       "3     soundscape_29201_20  0.003868  0.003786  0.003632  0.003703  0.003929   \n",
       "4     soundscape_29201_25  0.003871  0.003786  0.003632  0.003703  0.003931   \n",
       "..                    ...       ...       ...       ...       ...       ...   \n",
       "115  soundscape_29201_580  0.003873  0.003794  0.003635  0.003699  0.003932   \n",
       "116  soundscape_29201_585  0.003874  0.003792  0.003633  0.003699  0.003935   \n",
       "117  soundscape_29201_590  0.003875  0.003791  0.003634  0.003699  0.003934   \n",
       "118  soundscape_29201_595  0.003876  0.003792  0.003637  0.003700  0.003932   \n",
       "119  soundscape_29201_600  0.003874  0.003794  0.003636  0.003698  0.003932   \n",
       "\n",
       "      afecuc1   affeag1   afgfly1   afghor1  ...   yebsto1   yeccan1  \\\n",
       "0    0.003805  0.003747  0.003640  0.003671  ...  0.003826  0.003856   \n",
       "1    0.003801  0.003751  0.003645  0.003666  ...  0.003816  0.003860   \n",
       "2    0.003804  0.003748  0.003639  0.003670  ...  0.003821  0.003857   \n",
       "3    0.003805  0.003747  0.003641  0.003669  ...  0.003820  0.003857   \n",
       "4    0.003805  0.003746  0.003639  0.003671  ...  0.003824  0.003855   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "115  0.003806  0.003742  0.003636  0.003668  ...  0.003825  0.003856   \n",
       "116  0.003804  0.003744  0.003636  0.003666  ...  0.003825  0.003859   \n",
       "117  0.003803  0.003744  0.003638  0.003665  ...  0.003824  0.003859   \n",
       "118  0.003802  0.003745  0.003635  0.003659  ...  0.003819  0.003862   \n",
       "119  0.003803  0.003741  0.003637  0.003664  ...  0.003825  0.003859   \n",
       "\n",
       "       yefcan   yelbis1   yenspu1   yertin1   yesbar1   yespet1   yetgre1  \\\n",
       "0    0.003782  0.003615  0.003755  0.003804  0.003850  0.003718  0.003778   \n",
       "1    0.003780  0.003610  0.003756  0.003807  0.003849  0.003715  0.003780   \n",
       "2    0.003786  0.003616  0.003750  0.003800  0.003846  0.003724  0.003778   \n",
       "3    0.003785  0.003616  0.003751  0.003804  0.003849  0.003721  0.003778   \n",
       "4    0.003787  0.003616  0.003751  0.003806  0.003852  0.003723  0.003781   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "115  0.003789  0.003615  0.003745  0.003805  0.003849  0.003725  0.003783   \n",
       "116  0.003789  0.003612  0.003748  0.003804  0.003852  0.003722  0.003781   \n",
       "117  0.003786  0.003611  0.003746  0.003806  0.003851  0.003721  0.003783   \n",
       "118  0.003790  0.003612  0.003743  0.003802  0.003846  0.003727  0.003781   \n",
       "119  0.003788  0.003611  0.003745  0.003803  0.003847  0.003724  0.003782   \n",
       "\n",
       "      yewgre1  \n",
       "0    0.003703  \n",
       "1    0.003699  \n",
       "2    0.003708  \n",
       "3    0.003706  \n",
       "4    0.003705  \n",
       "..        ...  \n",
       "115  0.003704  \n",
       "116  0.003703  \n",
       "117  0.003703  \n",
       "118  0.003705  \n",
       "119  0.003704  \n",
       "\n",
       "[120 rows x 265 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([\n",
    "    pd.DataFrame({'row_id': [p['row_id'] for p in all_preds_flat]}), \n",
    "    pd.DataFrame(torch.stack([p['predictions'][0] for p in all_preds_flat]).numpy(), columns=label_encoder.classes_)\n",
    "], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0594aa8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:57.588973Z",
     "iopub.status.busy": "2023-04-14T04:40:57.587752Z",
     "iopub.status.idle": "2023-04-14T04:40:57.622280Z",
     "shell.execute_reply": "2023-04-14T04:40:57.620966Z"
    },
    "papermill": {
     "duration": 0.042766,
     "end_time": "2023-04-14T04:40:57.624993",
     "exception": false,
     "start_time": "2023-04-14T04:40:57.582227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fe05734",
   "metadata": {
    "papermill": {
     "duration": 0.003557,
     "end_time": "2023-04-14T04:40:57.917256",
     "exception": false,
     "start_time": "2023-04-14T04:40:57.913699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv\n"
     ]
    }
   ],
   "source": [
    "!ls submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71826b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.633397,
   "end_time": "2023-04-14T04:41:00.542795",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-14T04:40:32.909398",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
