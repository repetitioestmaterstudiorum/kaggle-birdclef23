{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ebd60c0",
   "metadata": {},
   "source": [
    "# RegNet Inference (submission generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b594cdc3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:42.750183Z",
     "iopub.status.busy": "2023-04-14T04:40:42.749779Z",
     "iopub.status.idle": "2023-04-14T04:40:47.150440Z",
     "shell.execute_reply": "2023-04-14T04:40:47.149088Z"
    },
    "papermill": {
     "duration": 4.409497,
     "end_time": "2023-04-14T04:40:47.153201",
     "exception": false,
     "start_time": "2023-04-14T04:40:42.743704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from torchvision.models import regnet_y_1_6gf, RegNet_Y_1_6GF_Weights\n",
    "import timm\n",
    "import re\n",
    "from torchaudio import functional as F_audio\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be457b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are running code on Localhost\n"
     ]
    }
   ],
   "source": [
    "## REUSE IN INFERENCE NOTEBOOK\n",
    "\n",
    "custom_dataset_path = '/kaggle/input/birdclef2023-inference'\n",
    "if os.path.exists(os.path.join(custom_dataset_path, 'utils.py')):\n",
    "    sys.path.append(custom_dataset_path)\n",
    "else:\n",
    "    sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "IS_IN_KAGGLE_ENV = utils.get_is_in_kaggle_env()\n",
    "\n",
    "DATA_PATH = '/kaggle/input/birdclef-2023' if IS_IN_KAGGLE_ENV else '../data'\n",
    "JOBLIB_PATH = custom_dataset_path if IS_IN_KAGGLE_ENV else './'\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "AUDIO_LENGTH_S = 5\n",
    "SAMPLE_RATE = 32_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2a40c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:47.281054Z",
     "iopub.status.busy": "2023-04-14T04:40:47.280329Z",
     "iopub.status.idle": "2023-04-14T04:40:47.286543Z",
     "shell.execute_reply": "2023-04-14T04:40:47.285263Z"
    },
    "papermill": {
     "duration": 0.013263,
     "end_time": "2023-04-14T04:40:47.289034",
     "exception": false,
     "start_time": "2023-04-14T04:40:47.275771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## REUSE IN INFERENCE NOTEBOOK\n",
    "\n",
    "class BirdMelspecClf(nn.Module):\n",
    "    def __init__(self, out_features, pretrained):\n",
    "        super().__init__()\n",
    "        \n",
    "        # https://pytorch.org/vision/stable/models.html\n",
    "        self.regnet = regnet_y_1_6gf(weights=RegNet_Y_1_6GF_Weights.DEFAULT) if pretrained else regnet_y_1_6gf()\n",
    "\n",
    "        \"\"\"\n",
    "        Replace the stem to take 2 channels instead of 3. The original stem:\n",
    "        (stem): SimpleStemIN(\n",
    "            (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): ReLU(inplace=True)\n",
    "            )\n",
    "        )\"\"\"\n",
    "        self.regnet.stem[0] = nn.Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        \n",
    "        # Replace original classifier: (fc): Linear(in_features=888, out_features=1000, bias=True)\n",
    "        self.regnet.fc = nn.Linear(self.regnet.fc.in_features, out_features)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        logits = self.regnet(x)\n",
    "        probas = self.softmax(logits)\n",
    "\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "def get_model(out_features, device, pretrained=False, load_state_dict=True, state_dict_starts_with=f\"{AUDIO_LENGTH_S}s_regnetY16GF\"):\n",
    "    model = BirdMelspecClf(out_features=out_features, pretrained=pretrained)\n",
    "    print(f\"Loaded model {model.__class__.__name__} with {sum(p.numel() for p in model.parameters())} parameters, pretained={pretrained}\")\n",
    "    model.to(device)\n",
    "\n",
    "    if not load_state_dict:\n",
    "        return model\n",
    "\n",
    "    model_files = [f for f in os.listdir(JOBLIB_PATH) if f.startswith(state_dict_starts_with) and f.endswith('.pt')]\n",
    "    if len(model_files) == 0:\n",
    "        print(f\"No model starting with {state_dict_starts_with} found in {JOBLIB_PATH}\")\n",
    "        return model\n",
    "    \n",
    "    # Extract timestamp from the filenames and sort based on it\n",
    "    model_files.sort(key=lambda x: int(re.findall(r'\\d+', x)[-1]) if re.findall(r'\\d+', x) else -1)\n",
    "\n",
    "    # The latest model file is the last one in the sorted list\n",
    "    latest_model_file = model_files[-1]\n",
    "    model_path = os.path.join(JOBLIB_PATH, latest_model_file)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Loaded model weights from {model_path}\")\n",
    "    model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_label_encoder():\n",
    "    label_encoder_path = os.path.join(JOBLIB_PATH, 'label_encoder.joblib')\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "    print(f\"Loaded label encoder from {label_encoder_path}\")\n",
    "    return label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a5798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletTransformSingle(nn.Module):\n",
    "  def __init__(\n",
    "      self, \n",
    "      wavelet: pywt.Wavelet,\n",
    "      cut_to_nearest: int | None = None\n",
    "  ):\n",
    "    super(WaveletTransformSingle, self).__init__()\n",
    "    self.wavelet = wavelet\n",
    "    self.ctn = cut_to_nearest\n",
    "\n",
    "  def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "    item = X.cpu().numpy()\n",
    "    \n",
    "    wh, wl = pywt.dwt(item[0], self.wavelet)\n",
    "    out = torch.stack((torch.from_numpy(wh), torch.from_numpy(wl)))\n",
    "    \n",
    "    if self.ctn is not None:\n",
    "      out = out[:,:-1 * (out.shape[-1] % self.ctn)]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456150a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:47.167665Z",
     "iopub.status.busy": "2023-04-14T04:40:47.167337Z",
     "iopub.status.idle": "2023-04-14T04:40:47.263629Z",
     "shell.execute_reply": "2023-04-14T04:40:47.262092Z"
    },
    "papermill": {
     "duration": 0.103522,
     "end_time": "2023-04-14T04:40:47.266309",
     "exception": false,
     "start_time": "2023-04-14T04:40:47.162787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## REUSE IN INFERENCE NOTEBOOK\n",
    "\n",
    "def resample(audio, current_sample_rate, desired_sample_rate=SAMPLE_RATE):\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=current_sample_rate, new_freq=desired_sample_rate)\n",
    "    resampled_audio = resampler(audio)\n",
    "    return resampled_audio\n",
    "\n",
    "def load_audio(audio_path, sample_rate=SAMPLE_RATE):\n",
    "    audio, sr = torchaudio.load(audio_path)\n",
    "    if sr != sample_rate:\n",
    "        audio = resample(audio, sr, sample_rate)\n",
    "    return audio\n",
    "\n",
    "# Using librosa defaults for n_fft and hop_length\n",
    "def get_melspec_transform(sample_rate=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    return torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "    )\n",
    "\n",
    "# Using librosa defaults for top_db\n",
    "def get_melspec_db_transform(stype='power', top_db=80):\n",
    "    return torchaudio.transforms.AmplitudeToDB(\n",
    "        stype=stype,\n",
    "        top_db=top_db\n",
    "    )\n",
    "\n",
    "# Copied from torchaudio/transforms/_transforms.py (to avoid converting to melspec twice)\n",
    "dct_mat = F_audio.create_dct(128, 128, \"ortho\")\n",
    "def get_mfcc_from_melspec(melspec):\n",
    "    return torch.matmul(melspec.transpose(-1, -2), dct_mat).transpose(-1, -2)\n",
    "\n",
    "def normalize_tensor(tensor):\n",
    "    min_val = torch.min(tensor)\n",
    "    max_val = torch.max(tensor)\n",
    "    if max_val - min_val == 0:\n",
    "        return tensor\n",
    "    else:\n",
    "        return (tensor - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ac267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepaths length: 1 (amount of test soundscapes)\n"
     ]
    }
   ],
   "source": [
    "filepaths = glob.glob(f\"{DATA_PATH}/test_soundscapes/*.ogg\")\n",
    "print(f\"filepaths length: {len(filepaths)} (amount of test soundscapes)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75cb3717",
   "metadata": {
    "papermill": {
     "duration": 0.002934,
     "end_time": "2023-04-14T04:40:48.158297",
     "exception": false,
     "start_time": "2023-04-14T04:40:48.155363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca7fea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:48.166858Z",
     "iopub.status.busy": "2023-04-14T04:40:48.165617Z",
     "iopub.status.idle": "2023-04-14T04:40:57.513978Z",
     "shell.execute_reply": "2023-04-14T04:40:57.512914Z"
    },
    "papermill": {
     "duration": 9.356216,
     "end_time": "2023-04-14T04:40:57.517571",
     "exception": false,
     "start_time": "2023-04-14T04:40:48.161355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded label encoder from ./label_encoder.joblib\n",
      "Loaded model BirdMelspecClf with 10548414 parameters, pretained=False\n",
      "No model starting with 5s_regnetY800MF found in ./\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infering files: 100%|██████████| 1/1 [00:00<00:00, 124.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_preds length: 1, all_preds_flat length: 120\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "debug = False\n",
    "simulate_200_files = False\n",
    "\n",
    "if simulate_200_files:\n",
    "    filepaths = [filepaths[0] for i in range(200)] # simulate submission\n",
    "    print(f\"filepaths length: {len(filepaths)} after simulation additions\")\n",
    "\n",
    "label_encoder = get_label_encoder()\n",
    "model = get_model(out_features=len(label_encoder.classes_), device=DEVICE, pretrained=False, load_state_dict=True)\n",
    "model.eval()\n",
    "\n",
    "MIN_WINDOW = AUDIO_LENGTH_S * SAMPLE_RATE\n",
    "melspec_transform = get_melspec_transform(n_mels=128)\n",
    "melspec_db_transform = get_melspec_db_transform()\n",
    "wave_transform = WaveletTransformSingle(pywt.Wavelet('sym4'))\n",
    "resize = transforms.Resize((128, 313), antialias=True)\n",
    "\n",
    "def infer(filepath):\n",
    "    all_predictions = []\n",
    "    name = Path(filepath).stem\n",
    "    audio = load_audio(filepath)\n",
    "    audio_len_s = audio.shape[1] / SAMPLE_RATE\n",
    "    debug and print(f\"Infering file {filepath} with length {audio_len_s} s\")\n",
    "    n_crops = int(audio_len_s // 5)\n",
    "    for i in range(n_crops):\n",
    "        debug and print(f\"Crop {i} / {n_crops}\")\n",
    "        debug and print(f\"Audio length: {len(audio)}\")\n",
    "        crop = audio[:, i*MIN_WINDOW:(i+1)*MIN_WINDOW]\n",
    "        debug and print(f\"Crop dimensions: {crop.shape}\")\n",
    "        melspec = melspec_db_transform(melspec_transform(crop))\n",
    "        norm_melspec = normalize_tensor(melspec)\n",
    "        melspec_wave = wave_transform(crop)\n",
    "        wh, wl = melspec_wave[0], melspec_wave[1]\n",
    "        wh_mel = melspec_db_transform(melspec_transform(wh))\n",
    "        wl_mel = melspec_db_transform(melspec_transform(wl))\n",
    "        norm_wh = normalize_tensor(resize(wh_mel.unsqueeze(0)))\n",
    "        norm_wl = normalize_tensor(resize(wl_mel.unsqueeze(0)))\n",
    "        mfcc = get_mfcc_from_melspec(melspec)\n",
    "        norm_mfcc = normalize_tensor(resize(mfcc))\n",
    "        features = torch.cat((norm_melspec, norm_wh, norm_wl, norm_mfcc), dim=0)\n",
    "        debug and print(f\"features shape: {features.shape}\") # [4, 128, 313]\n",
    "        features = features.unsqueeze(0) # add batch dimension (1)\n",
    "        debug and print(f\"features unsqueezed shape: {features.shape}\") # [1, 4, 128, 313]\n",
    "        with torch.no_grad():\n",
    "            logit, proba = model(features)\n",
    "        t = (i + 1) * 5\n",
    "        all_predictions.append({\"row_id\": f'{name}_{t}',\"predictions\": proba})\n",
    "        debug and print('---')\n",
    "    return all_predictions\n",
    "\n",
    "if debug:\n",
    "    all_preds = []\n",
    "    for filepath in tqdm(filepaths, desc='Infering files'):\n",
    "        all_preds.append(infer(filepath))\n",
    "else:\n",
    "    parallel_task = (delayed(infer)(filepath) for filepath in tqdm(filepaths, desc='Infering files'))\n",
    "    all_preds = Parallel(n_jobs=os.cpu_count())(parallel_task)\n",
    "\n",
    "all_preds_flat = [item for sublist in all_preds for item in sublist]\n",
    "\n",
    "print(f\"all_preds length: {len(all_preds)}, all_preds_flat length: {len(all_preds_flat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654b92e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0036, 0.0037, 0.0039, 0.0038, 0.0035, 0.0043, 0.0038, 0.0035, 0.0038,\n",
       "        0.0040, 0.0037, 0.0038, 0.0037, 0.0038, 0.0038, 0.0040, 0.0038, 0.0039,\n",
       "        0.0036, 0.0040, 0.0037, 0.0039, 0.0039, 0.0035, 0.0037, 0.0035, 0.0037,\n",
       "        0.0039, 0.0035, 0.0037, 0.0039, 0.0038, 0.0035, 0.0037, 0.0039, 0.0040,\n",
       "        0.0038, 0.0037, 0.0035, 0.0038, 0.0036, 0.0036, 0.0039, 0.0038, 0.0037,\n",
       "        0.0039, 0.0039, 0.0039, 0.0039, 0.0038, 0.0039, 0.0036, 0.0038, 0.0040,\n",
       "        0.0036, 0.0038, 0.0038, 0.0039, 0.0037, 0.0042, 0.0036, 0.0042, 0.0039,\n",
       "        0.0036, 0.0039, 0.0040, 0.0039, 0.0036, 0.0039, 0.0037, 0.0038, 0.0040,\n",
       "        0.0039, 0.0038, 0.0039, 0.0039, 0.0037, 0.0041, 0.0040, 0.0036, 0.0039,\n",
       "        0.0038, 0.0041, 0.0038, 0.0036, 0.0039, 0.0038, 0.0039, 0.0037, 0.0040,\n",
       "        0.0038, 0.0040, 0.0037, 0.0037, 0.0039, 0.0036, 0.0038, 0.0035, 0.0038,\n",
       "        0.0038, 0.0038, 0.0036, 0.0036, 0.0038, 0.0037, 0.0036, 0.0037, 0.0036,\n",
       "        0.0038, 0.0036, 0.0041, 0.0036, 0.0034, 0.0037, 0.0040, 0.0039, 0.0038,\n",
       "        0.0036, 0.0040, 0.0038, 0.0037, 0.0039, 0.0038, 0.0038, 0.0038, 0.0037,\n",
       "        0.0037, 0.0037, 0.0035, 0.0040, 0.0038, 0.0038, 0.0039, 0.0039, 0.0041,\n",
       "        0.0038, 0.0036, 0.0039, 0.0039, 0.0039, 0.0041, 0.0040, 0.0038, 0.0040,\n",
       "        0.0038, 0.0039, 0.0037, 0.0039, 0.0039, 0.0039, 0.0036, 0.0039, 0.0039,\n",
       "        0.0039, 0.0037, 0.0037, 0.0038, 0.0035, 0.0042, 0.0038, 0.0037, 0.0036,\n",
       "        0.0037, 0.0040, 0.0040, 0.0038, 0.0040, 0.0037, 0.0038, 0.0040, 0.0037,\n",
       "        0.0035, 0.0038, 0.0036, 0.0036, 0.0035, 0.0037, 0.0038, 0.0036, 0.0037,\n",
       "        0.0039, 0.0037, 0.0037, 0.0037, 0.0038, 0.0038, 0.0039, 0.0039, 0.0038,\n",
       "        0.0039, 0.0037, 0.0038, 0.0036, 0.0036, 0.0036, 0.0038, 0.0035, 0.0038,\n",
       "        0.0040, 0.0038, 0.0036, 0.0037, 0.0039, 0.0035, 0.0036, 0.0039, 0.0039,\n",
       "        0.0037, 0.0040, 0.0037, 0.0037, 0.0042, 0.0037, 0.0039, 0.0040, 0.0038,\n",
       "        0.0035, 0.0040, 0.0041, 0.0041, 0.0034, 0.0036, 0.0036, 0.0037, 0.0038,\n",
       "        0.0039, 0.0039, 0.0038, 0.0036, 0.0037, 0.0038, 0.0034, 0.0037, 0.0038,\n",
       "        0.0037, 0.0037, 0.0038, 0.0039, 0.0039, 0.0036, 0.0039, 0.0037, 0.0039,\n",
       "        0.0039, 0.0038, 0.0037, 0.0037, 0.0037, 0.0039, 0.0040, 0.0039, 0.0040,\n",
       "        0.0038, 0.0036, 0.0037, 0.0037, 0.0038, 0.0036, 0.0038, 0.0039, 0.0038,\n",
       "        0.0038, 0.0038, 0.0040])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds_flat[100]['predictions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77cb8d6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:57.528394Z",
     "iopub.status.busy": "2023-04-14T04:40:57.527976Z",
     "iopub.status.idle": "2023-04-14T04:40:57.575383Z",
     "shell.execute_reply": "2023-04-14T04:40:57.574650Z"
    },
    "papermill": {
     "duration": 0.055654,
     "end_time": "2023-04-14T04:40:57.577885",
     "exception": false,
     "start_time": "2023-04-14T04:40:57.522231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>abethr1</th>\n",
       "      <th>abhori1</th>\n",
       "      <th>abythr1</th>\n",
       "      <th>afbfly1</th>\n",
       "      <th>afdfly1</th>\n",
       "      <th>afecuc1</th>\n",
       "      <th>affeag1</th>\n",
       "      <th>afgfly1</th>\n",
       "      <th>afghor1</th>\n",
       "      <th>...</th>\n",
       "      <th>yebsto1</th>\n",
       "      <th>yeccan1</th>\n",
       "      <th>yefcan</th>\n",
       "      <th>yelbis1</th>\n",
       "      <th>yenspu1</th>\n",
       "      <th>yertin1</th>\n",
       "      <th>yesbar1</th>\n",
       "      <th>yespet1</th>\n",
       "      <th>yetgre1</th>\n",
       "      <th>yewgre1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_29201_5</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.003974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_29201_10</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.003980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_29201_15</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.003966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_29201_20</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.003967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_29201_25</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.003962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>soundscape_29201_580</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>0.003961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>soundscape_29201_585</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.003965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>soundscape_29201_590</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>0.003967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>soundscape_29201_595</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.003957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>soundscape_29201_600</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.003961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   row_id   abethr1   abhori1   abythr1   afbfly1   afdfly1  \\\n",
       "0      soundscape_29201_5  0.003633  0.003702  0.003929  0.003761  0.003518   \n",
       "1     soundscape_29201_10  0.003636  0.003699  0.003930  0.003759  0.003514   \n",
       "2     soundscape_29201_15  0.003634  0.003703  0.003930  0.003767  0.003530   \n",
       "3     soundscape_29201_20  0.003636  0.003702  0.003931  0.003763  0.003524   \n",
       "4     soundscape_29201_25  0.003637  0.003705  0.003932  0.003765  0.003527   \n",
       "..                    ...       ...       ...       ...       ...       ...   \n",
       "115  soundscape_29201_580  0.003631  0.003709  0.003924  0.003773  0.003537   \n",
       "116  soundscape_29201_585  0.003631  0.003709  0.003923  0.003768  0.003530   \n",
       "117  soundscape_29201_590  0.003632  0.003706  0.003926  0.003769  0.003529   \n",
       "118  soundscape_29201_595  0.003635  0.003710  0.003926  0.003777  0.003543   \n",
       "119  soundscape_29201_600  0.003631  0.003710  0.003925  0.003771  0.003534   \n",
       "\n",
       "      afecuc1   affeag1   afgfly1   afghor1  ...   yebsto1   yeccan1  \\\n",
       "0    0.004286  0.003805  0.003509  0.003754  ...  0.003642  0.003717   \n",
       "1    0.004290  0.003809  0.003506  0.003752  ...  0.003644  0.003719   \n",
       "2    0.004272  0.003799  0.003515  0.003751  ...  0.003650  0.003718   \n",
       "3    0.004278  0.003798  0.003512  0.003749  ...  0.003647  0.003719   \n",
       "4    0.004272  0.003796  0.003516  0.003750  ...  0.003649  0.003718   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "115  0.004262  0.003793  0.003532  0.003762  ...  0.003657  0.003714   \n",
       "116  0.004270  0.003795  0.003524  0.003760  ...  0.003653  0.003715   \n",
       "117  0.004271  0.003799  0.003524  0.003759  ...  0.003652  0.003716   \n",
       "118  0.004255  0.003788  0.003537  0.003762  ...  0.003665  0.003712   \n",
       "119  0.004267  0.003792  0.003527  0.003762  ...  0.003655  0.003715   \n",
       "\n",
       "       yefcan   yelbis1   yenspu1   yertin1   yesbar1   yespet1   yetgre1  \\\n",
       "0    0.003785  0.003596  0.003784  0.003925  0.003797  0.003750  0.003776   \n",
       "1    0.003791  0.003599  0.003784  0.003925  0.003797  0.003749  0.003773   \n",
       "2    0.003788  0.003598  0.003783  0.003921  0.003803  0.003751  0.003773   \n",
       "3    0.003789  0.003601  0.003781  0.003923  0.003801  0.003751  0.003773   \n",
       "4    0.003787  0.003600  0.003781  0.003921  0.003802  0.003750  0.003775   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "115  0.003788  0.003602  0.003786  0.003919  0.003801  0.003753  0.003772   \n",
       "116  0.003790  0.003599  0.003785  0.003920  0.003801  0.003754  0.003775   \n",
       "117  0.003787  0.003601  0.003785  0.003921  0.003797  0.003753  0.003772   \n",
       "118  0.003792  0.003604  0.003780  0.003916  0.003804  0.003754  0.003771   \n",
       "119  0.003787  0.003601  0.003784  0.003919  0.003801  0.003753  0.003773   \n",
       "\n",
       "      yewgre1  \n",
       "0    0.003974  \n",
       "1    0.003980  \n",
       "2    0.003966  \n",
       "3    0.003967  \n",
       "4    0.003962  \n",
       "..        ...  \n",
       "115  0.003961  \n",
       "116  0.003965  \n",
       "117  0.003967  \n",
       "118  0.003957  \n",
       "119  0.003961  \n",
       "\n",
       "[120 rows x 265 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([\n",
    "    pd.DataFrame({'row_id': [p['row_id'] for p in all_preds_flat]}), \n",
    "    pd.DataFrame(torch.stack([p['predictions'][0] for p in all_preds_flat]).numpy(), columns=label_encoder.classes_)\n",
    "], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0594aa8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:40:57.588973Z",
     "iopub.status.busy": "2023-04-14T04:40:57.587752Z",
     "iopub.status.idle": "2023-04-14T04:40:57.622280Z",
     "shell.execute_reply": "2023-04-14T04:40:57.620966Z"
    },
    "papermill": {
     "duration": 0.042766,
     "end_time": "2023-04-14T04:40:57.624993",
     "exception": false,
     "start_time": "2023-04-14T04:40:57.582227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe05734",
   "metadata": {
    "papermill": {
     "duration": 0.003557,
     "end_time": "2023-04-14T04:40:57.917256",
     "exception": false,
     "start_time": "2023-04-14T04:40:57.913699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv\n"
     ]
    }
   ],
   "source": [
    "!ls submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71826b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.633397,
   "end_time": "2023-04-14T04:41:00.542795",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-14T04:40:32.909398",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
