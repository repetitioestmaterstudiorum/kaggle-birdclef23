{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "import tqdm\n",
    "\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 21\n",
    "\n",
    "# Set seed for experiment reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_in_kaggle_env = utils.get_is_in_kaggle_env()\n",
    "\n",
    "data_path = '/kaggle/input/birdclef-2023/' if is_in_kaggle_env else '../data/'\n",
    "\n",
    "device = 'cpu' if is_in_kaggle_env else utils.determine_device()\n",
    "\n",
    "if not is_in_kaggle_env and not os.path.exists('../data'):\n",
    "    print(\"Downloading data...\")\n",
    "    !kaggle competitions download -c 'birdclef-2023'\n",
    "    !mkdir ../data\n",
    "    !unzip -q birdclef-2023.zip -d ../data\n",
    "    !rm birdclef-2023.zip\n",
    "\n",
    "df_metadata_csv = pd.read_csv(f\"{data_path}/train_metadata.csv\")\n",
    "\n",
    "audio_data_dir = f\"{data_path}/train_audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata_csv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata_csv[df_metadata_csv['filename'].str.contains(\"XC321277\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = df_metadata_csv.iloc[0, 11]\n",
    "print(f\"Audio path: {audio_path}\")\n",
    "\n",
    "primary_label = df_metadata_csv.iloc[0, 0]\n",
    "print(f\"Primary label: {primary_label}\")\n",
    "\n",
    "secondary_labels = df_metadata_csv.iloc[0, 1]\n",
    "print(f\"Secondary labels: {secondary_labels}\")\n",
    "\n",
    "file_id = audio_path.split('/')[-1].split('.')[0]\n",
    "print(f\"File ID: {file_id}\")\n",
    "\n",
    "print(f\"df length: {len(df_metadata_csv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df_metadata_csv[\"primary_label\"].value_counts()\n",
    "\n",
    "two_or_less_samples_rows = df_metadata_csv[df_metadata_csv[\"primary_label\"].isin(class_counts[class_counts < 3].index)]\n",
    "\n",
    "print(f\"Number of unique classes with less than 2 samples: {len(two_or_less_samples_rows['primary_label'].unique())}\")\n",
    "print(f\"Number of rows with less than 2 samples: {len(two_or_less_samples_rows)}\")\n",
    "print(f\"Primary labels with less than 2 samples: {two_or_less_samples_rows['primary_label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with primary_label that have two or less samples\n",
    "print(f\"Number of rows before dropping: {len(df_metadata_csv)}\")\n",
    "df_metadata_csv = df_metadata_csv[~df_metadata_csv[\"primary_label\"].isin(class_counts[class_counts < 3].index)]\n",
    "print(f\"Number of rows after dropping: {len(df_metadata_csv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each row of a 10% random sample of train_df, get the audio file length, and add it to a list, show the progress using tqdm\n",
    "\n",
    "audio_lengths_s = []\n",
    "for i, row in tqdm.tqdm(df_metadata_csv.sample(frac=0.1).iterrows(), total=int(len(df_metadata_csv) * 0.1)):\n",
    "    audio_path = row[\"filename\"]\n",
    "    audio_path = f\"{audio_data_dir}/{audio_path}\"\n",
    "    audio, sr = librosa.load(audio_path)\n",
    "    audio_lengths_s.append(len(audio) / sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the audio lengths\n",
    "plt.hist(audio_lengths_s, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the audio lengths as histogram until 80th percentile\n",
    "plt.hist(audio_lengths_s, bins=1000)\n",
    "plt.xlim(0, np.percentile(audio_lengths_s, 80))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(audio_lengths_s), min(audio_lengths_s), np.percentile(audio_lengths_s, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(audio_lengths_s), np.median(audio_lengths_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Get unique classes\n",
    "unique_primary_classes = df_metadata_csv.primary_label.unique()\n",
    "\n",
    "secondary_classes = df_metadata_csv.secondary_labels.tolist()\n",
    "unique_secondary_classes = set()\n",
    "for class_list_str in secondary_classes:\n",
    "    class_list = ast.literal_eval(class_list_str)\n",
    "    for c in class_list:\n",
    "        unique_secondary_classes.add(c)\n",
    "\n",
    "classes = set(unique_primary_classes).union(unique_secondary_classes)\n",
    "print(f\"Number of classes: {len(classes)}\")\n",
    "\n",
    "classes_in_secondary_but_not_primary = unique_secondary_classes.difference(unique_primary_classes)\n",
    "print(f\"Number of classes in secondary but not primary: {len(classes_in_secondary_but_not_primary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
